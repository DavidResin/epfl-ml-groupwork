\documentclass[10pt,conference,compsocconf]{IEEEtran}

\usepackage{hyperref}
\usepackage{graphicx}	% For figure environment

\begin{document}
\title{Class Project 1}

\author{%
  Saskia Reiss, Alvaro Pinedo and David Resin\\%
  CS-433 -- Machine Learning\\EPFL, Switzerland%
}

\maketitle

\begin{abstract}
TODO SUMMARY
\end{abstract}

\section{Introduction}
\section{Methodology}
First, we extract the data from the \texttt{.csv} files using the provided function \texttt{load\_csv\_data}. For each file it returns us the predictions \texttt{y} (which is of course empty in the case of the test data), the data \texttt{x}, and the sample identifiers \texttt{ids}. We defined the function \texttt{triage} which replaces all $-999$ values in the document, which are placeholders for unavailable data, with the mean of the column they are in. We consider this to be the best way to treat these values without splitting up the data into different categories. We decided not to normalize the data as it resulted in overfitting. We then use the \texttt{build\_poly} method with degree 9 on both datasets, before applying \texttt{least\_squares} on the training data set and feed the resulting weigths to \texttt{predict\_labels} along with the testing dataset.
\section{Results}
\begin{itemize}
\item Our first attempt simply used \texttt{least\_squares} on the unaltered dataset, which gave us a score of \textbf{0.74463}.
\item We then improved our results by applying \texttt{build\_poly} with degree 7 and feeding the result to \texttt{least\_squares}, which gave us a new best score of \textbf{0.80061}.
\item Our next improvement  consisted of replacing all $-999$ values in the dataset with 0's instead for a score of \textbf{0.80596}.
\item Replacing $-999$ values with the column average instead along with building polys of degree 9 raised our best score to \textbf{0.81553}.
\end{itemize}
\section{Discussion}
\section{Conclusion}



\end{document}
