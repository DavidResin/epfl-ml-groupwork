{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Text Frequency-Inverse Document Frequency (TF-IDF) Implementation</h1>\n",
    "\n",
    "In this notebook we implement a TF-IDF vectorizer and use it on two models (classifiers) to get predictions: a Multinomial Naive Bayes and a Support Vector Machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Needed general imports\n",
    "import csv, pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Sklearn libraries for TF-IDF and specific classifiers (Bayes and SVM)\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we get the DataFrames we saved before to use them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('outputs/train_neg_proc.pkl', 'rb') as f:\n",
    "    neg_DF = pickle.load(f)\n",
    "    \n",
    "with open('outputs/train_pos_proc.pkl', 'rb') as f:\n",
    "    pos_DF = pickle.load(f)\n",
    "    \n",
    "with open('outputs/test_data_proc.pkl', 'rb') as f:\n",
    "    test_DF = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_DF.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>TF-IDF</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we create the vectorizer. We go with the idea that we do not want the words that appear in less than 5 tweets and in more than 80% of the tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create the vectoriser\n",
    "vectorizer = TfidfVectorizer(min_df=5, max_df = 0.8, sublinear_tf=True, use_idf =True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now need to create a corpus. Our train set is both positive and negative set appended to each other, and our test set is, obviously, the unlabeled part.\n",
    "\n",
    "To do this, we will append both negative and positive DF, then create a matrix of labels for them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# put the list of words into a usable format\n",
    "neg_DF = neg_DF[\"lemmed\"]\n",
    "pos_DF = pos_DF[\"lemmed\"]\n",
    "test_DF = test_DF[\"lemmed\"]\n",
    "neg_DF = pd.DataFrame(neg_DF)\n",
    "pos_DF = pd.DataFrame(pos_DF)\n",
    "test_DF = pd.DataFrame(test_DF)\n",
    "neg_DF[\"lemmed\"] = neg_DF.lemmed.apply(' '.join)\n",
    "pos_DF[\"lemmed\"] = pos_DF.lemmed.apply(' '.join)\n",
    "test_DF[\"lemmed\"] = test_DF.lemmed.apply(' '.join)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# we thus know that all the first ones are labeled as -1 and all the others as 1\n",
    "all_labeled_DF = pd.concat([neg_DF, pos_DF])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# we create the labels\n",
    "negs = len(neg_DF.index)\n",
    "poss = len(pos_DF.index)\n",
    "labels = np.zeros(negs+poss)\n",
    "labels[0:negs]=-1\n",
    "labels[negs:negs+poss]=1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we train our TF-IDF vectorizer on the training set\n",
    "train_corpus_tf_idf = vectorizer.fit_transform(all_labeled_DF['lemmed'])\n",
    "# we fit our TF-IDF vectorizer on the test set\n",
    "test_corpus_tf_idf = vectorizer.transform(test_DF[\"lemmed\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that this is done, it is time to test out this vectorizer on the two classifiers mentioned above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# we create both models\n",
    "model1 = LinearSVC() # SVM\n",
    "model2 = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train on the given models\n",
    "model1.fit(train_corpus_tf_idf,labels)\n",
    "model2.fit(train_corpus_tf_idf,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# predictions\n",
    "result1 = model1.predict(test_corpus_tf_idf)\n",
    "result2 = model2.predict(test_corpus_tf_idf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Result1 and result2 are the labels predicted for the tweets we got in the test corpus. This means we just have to transform this into a .csv, as shown in the sample submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Converting it to integer for prediction .csv\n",
    "result1 = [int(x) for x in result1]\n",
    "result2 = [int(x) for x in result2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_csv(df, filename):\n",
    "    # Creating the correctly named columns for the .csv\n",
    "    df['Id'] = df.index + 1\n",
    "    df['Prediction'] = df[0]\n",
    "    df = df[['Id', 'Prediction']]\n",
    "    # Saving prediction to .csv\n",
    "    df.to_csv('outputs/' + filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creating a DataFrame for easy .csv transformation\n",
    "svm_df = pd.DataFrame(result1)\n",
    "create_csv(svm_df, 'svm.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creating a DataFrame for easy .csv transformation\n",
    "bayes_df = pd.DataFrame(result2)\n",
    "create_csv(bayes_df, 'bayes.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
